{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python363jvsc74a57bd0b425d78e4af0bd3c23a81902e2758eade18cf5e151c20ebf28251a6ca45ac438",
   "display_name": "Python 3.6.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'D:\\kaggle\\datasets\\digit-recognizer\\train.csv')\n",
    "test  = pd.read_csv(r'D:\\kaggle\\datasets\\digit-recognizer\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.values[:,1:]\n",
    "Y_train = train.values[:,0]\n",
    "test=test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "test = test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 251.565 248.518125 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g clip-path=\"url(#p8839add199)\">\r\n    <image height=\"218\" id=\"image6cbeea6bc6\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.64\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p8839add199\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plot_digit(X_train[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "#对于黑白图像（比如 MNIST 数字图像），深度等于 1（表示灰度等级）。\n",
    "#学到的就是在输入图像的二维小窗口中发现的模式。这些窗口的大小都是 3×3。\n",
    "#Conv2D(output_depth,(window_height, window_width))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 11, 11, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 5, 5, 64)          0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 3, 3, 64)          36928     \n=================================================================\nTotal params: 55,744\nTrainable params: 55,744\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将 3D 输出展平为 1D，然后在上面添加几个 Dense 层\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_5 (Conv2D)            (None, 26, 26, 32)        320       \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 13, 13, 32)        0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 11, 11, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 5, 5, 64)          0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 3, 3, 64)          36928     \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 576)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                36928     \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 93,322\nTrainable params: 93,322\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "random_seed = 42\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(37800, 28, 28, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(37800,)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4200,)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "\n",
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4200, 28, 28, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "Y_train = to_categorical(Y_train)\n",
    "Y_val = to_categorical(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import  RMSprop\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=optimizer,\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "learning_rate_reductions = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                            patience = 3,\n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # 使输入数据集去中心化（均值为0）, 按feature执行\n",
    "        samplewise_center=False,  # 使输入数据的每个样本均值为0\n",
    "        featurewise_std_normalization=False,  # 将输入除以数据集的标准差以完成标准化, 按feature执行\n",
    "        samplewise_std_normalization=False,  # 将输入的每个样本除以其自身的标准差\n",
    "        zca_whitening=False,  # 对输入数据施加ZCA白化\n",
    "        rotation_range=10,  # 数据增强时图片随机转动的角度\n",
    "        zoom_range = 0.1, # 随机缩放的幅度\n",
    "        width_shift_range=0.1,  # 图片宽度的某个比例，数据增强时图片水平偏移的幅度\n",
    "        height_shift_range=0.1,  # 图片高度的某个比例，数据增强时图片竖直偏移的幅度\n",
    "        horizontal_flip=False,  # 进行随机水平翻转\n",
    "        vertical_flip=False)  # 进行随机竖直翻转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "X_train.shape[0]//100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0797 - accuracy: 0.9756 - val_loss: 0.0309 - val_accuracy: 0.9898\n",
      "Epoch 2/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0789 - accuracy: 0.9774 - val_loss: 0.0275 - val_accuracy: 0.9914\n",
      "Epoch 3/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0740 - accuracy: 0.9778 - val_loss: 0.0263 - val_accuracy: 0.9910\n",
      "Epoch 4/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0717 - accuracy: 0.9790 - val_loss: 0.0265 - val_accuracy: 0.9924\n",
      "Epoch 5/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0712 - accuracy: 0.9797 - val_loss: 0.0262 - val_accuracy: 0.9912\n",
      "Epoch 6/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0642 - accuracy: 0.9810 - val_loss: 0.0262 - val_accuracy: 0.9917\n",
      "Epoch 7/30\n",
      "376/378 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9816\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0613 - accuracy: 0.9816 - val_loss: 0.0283 - val_accuracy: 0.9917\n",
      "Epoch 8/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0524 - accuracy: 0.9843 - val_loss: 0.0242 - val_accuracy: 0.9924\n",
      "Epoch 9/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0534 - accuracy: 0.9855 - val_loss: 0.0206 - val_accuracy: 0.9929\n",
      "Epoch 10/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0526 - accuracy: 0.9843 - val_loss: 0.0215 - val_accuracy: 0.9933\n",
      "Epoch 11/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0539 - accuracy: 0.9853 - val_loss: 0.0204 - val_accuracy: 0.9933\n",
      "Epoch 12/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0511 - accuracy: 0.9849 - val_loss: 0.0204 - val_accuracy: 0.9931\n",
      "Epoch 13/30\n",
      "377/378 [============================>.] - ETA: 0s - loss: 0.0518 - accuracy: 0.9847\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0518 - accuracy: 0.9847 - val_loss: 0.0209 - val_accuracy: 0.9931\n",
      "Epoch 14/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0458 - accuracy: 0.9862 - val_loss: 0.0209 - val_accuracy: 0.9933\n",
      "Epoch 15/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0457 - accuracy: 0.9867 - val_loss: 0.0200 - val_accuracy: 0.9943\n",
      "Epoch 16/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0452 - accuracy: 0.9869 - val_loss: 0.0187 - val_accuracy: 0.9938\n",
      "Epoch 17/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0444 - accuracy: 0.9878 - val_loss: 0.0199 - val_accuracy: 0.9926\n",
      "Epoch 18/30\n",
      "376/378 [============================>.] - ETA: 0s - loss: 0.0456 - accuracy: 0.9869\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0456 - accuracy: 0.9869 - val_loss: 0.0184 - val_accuracy: 0.9931\n",
      "Epoch 19/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0460 - accuracy: 0.9878 - val_loss: 0.0178 - val_accuracy: 0.9940\n",
      "Epoch 20/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0416 - accuracy: 0.9876 - val_loss: 0.0184 - val_accuracy: 0.9936\n",
      "Epoch 21/30\n",
      "378/378 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9882\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0412 - accuracy: 0.9882 - val_loss: 0.0179 - val_accuracy: 0.9943\n",
      "Epoch 22/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0399 - accuracy: 0.9889 - val_loss: 0.0174 - val_accuracy: 0.9940\n",
      "Epoch 23/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0409 - accuracy: 0.9882 - val_loss: 0.0165 - val_accuracy: 0.9940\n",
      "Epoch 24/30\n",
      "378/378 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9882\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0407 - accuracy: 0.9882 - val_loss: 0.0178 - val_accuracy: 0.9943\n",
      "Epoch 25/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0387 - accuracy: 0.9886 - val_loss: 0.0172 - val_accuracy: 0.9945\n",
      "Epoch 26/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0382 - accuracy: 0.9890 - val_loss: 0.0174 - val_accuracy: 0.9945\n",
      "Epoch 27/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0428 - accuracy: 0.9883 - val_loss: 0.0172 - val_accuracy: 0.9945\n",
      "Epoch 28/30\n",
      "376/378 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9887\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0403 - accuracy: 0.9887 - val_loss: 0.0168 - val_accuracy: 0.9945\n",
      "Epoch 29/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0392 - accuracy: 0.9887 - val_loss: 0.0171 - val_accuracy: 0.9943\n",
      "Epoch 30/30\n",
      "378/378 [==============================] - 7s 18ms/step - loss: 0.0402 - accuracy: 0.9888 - val_loss: 0.0169 - val_accuracy: 0.9943\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(datagen.flow(X_train,Y_train,batch_size = 100),\n",
    "                            epochs=30,validation_data=(X_val,Y_val),verbose=1,steps_per_epoch=378,callbacks=[learning_rate_reductions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(X_train,Y_train,epochs=5,batch_size=64,validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.argmax(results,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.Series(results, name = 'Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    2\n",
       "1    0\n",
       "2    9\n",
       "3    9\n",
       "4    3\n",
       "Name: Label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"cnn_mnist_datagen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}